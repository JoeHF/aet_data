% Documentation for pkuthss.
%
% Copyright (c) 2008-2009 solvethis
% Copyright (c) 2010-2012,2014-2015 Casper Ti. Vector
%
% This work may be distributed and/or modified under the conditions of the
% LaTeX Project Public License, either version 1.3 of this license or (at
% your option) any later version.
% The latest version of this license is in
%   https://www.latex-project.org/lppl.txt
% and version 1.3 or later is part of all distributions of LaTeX version
% 2005/12/01 or later.
%
% This work has the LPPL maintenance status `maintained'.
% The current maintainer of this work is Casper Ti. Vector.
%
% This work consists of the following files:
%   pkuthss.tex
%   chap/pkuthss-copyright.tex
%   chap/pkuthss-abstract.tex
%   chap/pkuthss-introduction.tex
%   chap/pkuthss-chap1.tex
%   chap/pkuthss-chap2.tex
%   chap/pkuthss-chap3.tex
%   chap/pkuthss-conclusion.tex
%   chap/pkuthss-encl1.tex
%   chap/pkuthss-acknowledge.tex

\chapter{序言}

随着互联网的高速发展，云计算正在被越来越多的用户使用。云计算的目标是将各种IT资源以服务的方式通过互联网交付给用户。计算资源、存储资源、软件开发、系统测试、系统维护和各种丰富的应用服务，都将像水和电一样方便地被使用，并可按量计费。云计算让用户能够收益于当前主流的技术而无需深入的了解和掌握他们，旨在降低成本和帮助用户专注于他们的核心业务，而不是让IT成为他们的阻碍。

虚拟化实现了IT资源的逻辑抽象和统一表示，在大规模数据中心管理和解决方案交付方面发挥着巨大的作用，是支撑云计算伟大构想的最重要的技术基石。虚拟化提供了隔离多个虚拟机的能力，多个虚拟机能够共享一个物理主机并且做到相互之间的隔离。虚拟化对于资源的整合，计算机安全都起到了重要的作用。

云计算厂商在销售虚拟机的时候为了达到资源的最大化利用，往往会进行超卖，超卖顾名思义就是一个物理机上的虚拟机配置总和超过了物理资源上限，CPU可以超卖，内存可以超卖，带宽也能够超卖。超卖的缺点不言而喻，当一个物理机上的所有虚拟机都在剧烈使用资源时就会导致物理资源紧张，各个虚拟机的性能就会显著地下降最终会影响到用户的体验。可能绝大多数的时候虚拟机超卖不会对虚拟机性能产生很大影响，但是即便是很小概率出现资源缺乏对于使用服务的用户来说都是不可接受的。所以对虚拟机资源使用的预测成为了关键，当虚拟机管理器侦测到了物理资源不足时，就需要将资源短缺物理机上的虚拟机迁移到相对空闲的物理机上从而保证虚拟机性能。本文旨在寻找一种在虚拟化环境下对虚拟机内存资源进行预测的高效而准确的方法。

计算机的内存管理使用的是页式管理，应用程序使用到的内存地址是虚拟地址，虚拟地址需要经过内存管理单元(MMU)的翻译转换成物理地址才能真正访问内存。其中的地址转换用到的是页表，页表保存在内存中，为了降低地址转换所带来的访存数，在处理器里又添加了转译后备缓冲器(TLB)加速地址转化。

而在虚拟化环境下，这样一层地址转化是不够的，虚拟机之间感受不到对方的存在，他们会认为自己独占整个物理内存空间，因此虚拟机的地址翻译可能会将同一块物理地址分配个不同的虚拟机，这就无法实现虚拟机之间的隔离和数据的安全。为了实现内存虚拟化，让客户机使用一个隔离的、从零开始且连续的内存空间，虚拟机管理器会引入一层额外的地址空间，称为客户机物理地址空间(Guest Physical Address, GPA)。这个地址空间并不是真正的物理地址空间，只是虚拟机虚拟地址空间映射到的物理地址空间，对于虚拟机来说GPA是连续且从零开始的，GPA还需要进一步的地址转换映射到真正的物理机的物理地址上。GPA不能用作物理机内存寻址，还需要做一个转化，在全虚拟化下通常有两种方法能够做到，影子页表和EPT页表，他们都通过建立GPA到物理地址映射来实现。

内存虚拟化是实现虚拟机内存隔离的手段，为了保证内存资源的有效利用，还需要用到内存调度，当虚拟机内存不足时增加虚拟机的内存，内存富裕时让出内存，内存调度用到的技术是气球驱动技术，它是虚拟机操作系统里的一个模块，通过充气和放气来分别回收和返还内存，通过充气回收的内存交给虚拟机管理器管理供其他虚拟机使用。

有了内存虚拟化我们能够实现虚拟机内存的隔离，有了气球驱动我们能够调整虚拟机的内存大小，然而最具有挑战性的问题是如何预测虚拟机的内存使用。工作集理论(WSS)\parencite{wss}定义一个进程在t时刻的工作集$W(t, \tau)$为进程在$(t - \tau, t)$时间段里访问到的内存大小。 但是工作集理论有一定的缺陷，它并不直接和应用程序的性能相关。比如一个应用程序顺序扫描100个页面，那么在这个短暂周期里面，它的工作集大小就是100页，但是给这个应用程序分配一个页面或者100个页面的内存缺失率是一样的，这个缺失率都是100\%。 另外一个更好的方法是使用失效率曲线(Miss Ratio Curve, MRC)来刻画内存大小和性能之间的关系，MRC能够反映在不同缓存大小下的缓存失效率，这里的缓存概念是宽泛的，可以是CPU和主内存之间的缓存(cache)，也可以是内存和磁盘之间的磁盘缓存(disk cache)，当然内存也可以看作是磁盘的缓存。传统的计算MRC的办法是使用LRU栈算法\parencite{Mattson1970Evaluation}，使用LRU链表去模拟缓存的写入替换，由于链表的插入移动开销都是$O(n)$，所以算法的时间复杂度很高，对于LRU栈算法有平衡树优化算法能够将缓存块查询移动开销降低到$O(logn)$，不过这样的开销仍然不适用于在线MRC计算。最新的研究AET算法\parencite{aet}使用采样的方法能够将计算MRC的时间开销和空间开销降低到可接受的范围，是目前最有可能实现在线内存预测的算法，LRU栈算法是经典的MRC计算算法，AET算法是基于概率模型的算法，所以其正确性和真正的开销还有待验证。

针对在现有研究成果下做在线MRC计算的难点，尤其是在虚拟化环境下如何将预测虚拟机内存的开销降低到可容许的范围，本文做出了如下的贡献：
\begin{itemize}
\item 实现了一套能够在xen虚拟化环境下进行内存工作集预测的系统
\item 这个内存工作集预测系统能够实现多种预测方法，包括LRU栈算法以及性能更加出色的AET算法
\item 通过比较AET算法计算的MRC曲线和使用LRU算法计算出的MRC曲线，验证了AET算法在内存工作集预测里的可行性
\item 提出动态采样率算法，通过控制采样率将虚拟机内存预测的平均开销控制在2\%
\end{itemize}

本文后续章节的组织方式如下：
\begin{itemize}
\item 第一章介绍工作集预测常用的手段——MRC曲线，介绍了传统的计算MRC算法，以及MRC在多层次存储结构下的应用，最后引入AET算法，介绍一个低空间开销，高效的计算MRC算法。
\item 第二章介绍linux下页面管理方法以及在全虚拟化下内存虚拟化的方式。
\item 第三章将AET算法引入全虚拟化下的内存工作集预测，设计和实现了一个高效可管理的内存工作集预测系统。
\item 第四章对本文实现的全虚拟化下内存工作集预测系统的正确性、可行性进行实验分析。
\item 第五章介绍一下相关工作。
\end{itemize}
% vim:ts=4:sw=4
